# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-23 11:24+0800\n"
"PO-Revision-Date: 2026-01-22 10:00+0800\n"
"Last-Translator: Your Name <email@example.com>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/tutorials/DeepSeek-V3.2.md:1
msgid "DeepSeek-V3.2"
msgstr "DeepSeek-V3.2"

#: ../../source/tutorials/DeepSeek-V3.2.md:3
msgid "Introduction"
msgstr "简介"

#: ../../source/tutorials/DeepSeek-V3.2.md:5
msgid ""
"DeepSeek-V3.2 is a sparse attention model. The main architecture is "
"similar to DeepSeek-V3.1, but with a sparse attention mechanism, which is"
" designed to explore and validate optimizations for training and "
"inference efficiency in long-context scenarios."
msgstr ""
"DeepSeek-V3.2 是一个稀疏注意力模型。其主要架构与 DeepSeek-V3.1 "
"相似，但采用了稀疏注意力机制，旨在探索和验证长上下文场景中训练和推理效率的优化。"

#: ../../source/tutorials/DeepSeek-V3.2.md:7
msgid ""
"This document will show the main verification steps of the model, "
"including supported features, feature configuration, environment "
"preparation, single-node and multi-node deployment, accuracy and "
"performance evaluation."
msgstr "本文档将展示该模型的主要验证步骤，包括支持的特性、特性配置、环境准备、单节点和多节点部署、精度和性能评估。"

#: ../../source/tutorials/DeepSeek-V3.2.md:9
msgid "Supported Features"
msgstr "支持的特性"

#: ../../source/tutorials/DeepSeek-V3.2.md:11
msgid ""
"Refer to [supported "
"features](../user_guide/support_matrix/supported_models.md) to get the "
"model's supported feature matrix."
msgstr "请参考[支持的特性](../user_guide/support_matrix/supported_models.md)以获取模型支持的特性矩阵。"

#: ../../source/tutorials/DeepSeek-V3.2.md:13
msgid ""
"Refer to [feature guide](../user_guide/feature_guide/index.md) to get the"
" feature's configuration."
msgstr "请参考[特性指南](../user_guide/feature_guide/index.md)以获取特性的配置信息。"

#: ../../source/tutorials/DeepSeek-V3.2.md:15
msgid "Environment Preparation"
msgstr "环境准备"

#: ../../source/tutorials/DeepSeek-V3.2.md:17
msgid "Model Weight"
msgstr "模型权重"

#: ../../source/tutorials/DeepSeek-V3.2.md:19
msgid ""
"`DeepSeek-V3.2-Exp`(BF16 version): require 2 Atlas 800 A3 (64G × 16) "
"nodes or 4 Atlas 800 A2 (64G × 8) nodes. [Download model "
"weight](https://modelers.cn/models/Modelers_Park/DeepSeek-V3.2-Exp-BF16)"
msgstr ""
"`DeepSeek-V3.2-Exp`(BF16 版本)：需要 2 台 Atlas 800 A3 (64G × 16) 节点或 4 台 Atlas"
" 800 A2 (64G × 8) "
"节点。[下载模型权重](https://modelers.cn/models/Modelers_Park/DeepSeek-V3.2-Exp-"
"BF16)"

#: ../../source/tutorials/DeepSeek-V3.2.md:20
msgid ""
"`DeepSeek-V3.2-Exp-w8a8`(Quantized version): require 1 Atlas 800 A3 (64G "
"× 16) node or 2 Atlas 800 A2 (64G × 8) nodes. [Download model "
"weight](https://modelers.cn/models/Modelers_Park/DeepSeek-V3.2-Exp-w8a8)"
msgstr ""
"`DeepSeek-V3.2-Exp-w8a8`(量化版本)：需要 1 台 Atlas 800 A3 (64G × 16) 节点或 2 台 "
"Atlas 800 A2 (64G × 8) "
"节点。[下载模型权重](https://modelers.cn/models/Modelers_Park/DeepSeek-V3.2-Exp-"
"w8a8)"

#: ../../source/tutorials/DeepSeek-V3.2.md:21
msgid ""
"`DeepSeek-V3.2`(BF16 version): require 2 Atlas 800 A3 (64G × 16) nodes or"
" 4 Atlas 800 A2 (64G × 8) nodes. Model weight in BF16 not found now."
msgstr ""
"`DeepSeek-V3.2`(BF16 版本)：需要 2 台 Atlas 800 A3 (64G × 16) 节点或 4 台 Atlas 800"
" A2 (64G × 8) 节点。目前未找到 BF16 格式的模型权重。"

#: ../../source/tutorials/DeepSeek-V3.2.md:22
msgid ""
"`DeepSeek-V3.2-w8a8`(Quantized version): require 1 Atlas 800 A3 (64G × "
"16) node or 2 Atlas 800 A2 (64G × 8) nodes. [Download model "
"weight](https://www.modelscope.cn/models/vllm-ascend/DeepSeek-V3.2-W8A8/)"
msgstr ""
"`DeepSeek-V3.2-w8a8`(量化版本)：需要 1 台 Atlas 800 A3 (64G × 16) 节点或 2 台 Atlas "
"800 A2 (64G × 8) 节点。[下载模型权重](https://www.modelscope.cn/models/vllm-"
"ascend/DeepSeek-V3.2-W8A8/)"

#: ../../source/tutorials/DeepSeek-V3.2.md:24
msgid ""
"It is recommended to download the model weight to the shared directory of"
" multiple nodes, such as `/root/.cache/`"
msgstr "建议将模型权重下载到多个节点的共享目录中，例如 `/root/.cache/`"

#: ../../source/tutorials/DeepSeek-V3.2.md:26
msgid "Verify Multi-node Communication(Optional)"
msgstr "验证多节点通信（可选）"

#: ../../source/tutorials/DeepSeek-V3.2.md:28
msgid ""
"If you want to deploy multi-node environment, you need to verify multi-"
"node communication according to [verify multi-node communication "
"environment](../installation.md#verify-multi-node-communication)."
msgstr ""
"如果要部署多节点环境，需要根据[验证多节点通信环境](../installation.md#verify-multi-node-"
"communication)验证多节点通信。"

#: ../../source/tutorials/DeepSeek-V3.2.md:30
msgid "Installation"
msgstr "安装"

#: ../../source/tutorials/DeepSeek-V3.2.md:32
msgid "You can using our official docker image to run `DeepSeek-V3.2` directly.."
msgstr "您可以使用我们的官方 docker 镜像直接运行 `DeepSeek-V3.2`。"

#: ../../source/tutorials/DeepSeek-V3.2.md
msgid "A3 series"
msgstr "A3 系列"

#: ../../source/tutorials/DeepSeek-V3.2.md:41
#: ../../source/tutorials/DeepSeek-V3.2.md:84
msgid "Start the docker image on your each node."
msgstr "在每个节点上启动 docker 镜像。"

#: ../../source/tutorials/DeepSeek-V3.2.md
msgid "A2 series"
msgstr "A2 系列"

#: ../../source/tutorials/DeepSeek-V3.2.md:117
msgid ""
"In addition, if you don't want to use the docker image as above, you can "
"also build all from source:"
msgstr "此外，如果您不想使用上述 docker 镜像，也可以从源代码构建所有内容："

#: ../../source/tutorials/DeepSeek-V3.2.md:119
msgid ""
"Install `vllm-ascend` from source, refer to "
"[installation](../installation.md)."
msgstr "从源代码安装 `vllm-ascend`，请参考[安装](../installation.md)。"

#: ../../source/tutorials/DeepSeek-V3.2.md:121
msgid ""
"If you want to deploy multi-node environment, you need to set up "
"environment on each node."
msgstr "如果要部署多节点环境，需要在每个节点上设置环境。"

#: ../../source/tutorials/DeepSeek-V3.2.md:123
msgid "Deployment"
msgstr "部署"

#: ../../source/tutorials/DeepSeek-V3.2.md:126
msgid ""
"In this tutorial, we suppose you downloaded the model weight to "
"`/root/.cache/`. Feel free to change it to your own path."
msgstr "在本教程中，我们假设您将模型权重下载到了 `/root/.cache/`。请随时更改为您自己的路径。"

#: ../../source/tutorials/DeepSeek-V3.2.md:129
msgid "Prefill-Decode Disaggregation"
msgstr "预填充-解码分离"

#: ../../source/tutorials/DeepSeek-V3.2.md:131
msgid ""
"We'd like to show the deployment guide of `DeepSeek-V3.2` on multi-node "
"environment with 1P1D for better performance."
msgstr "我们将展示 `DeepSeek-V3.2` 在多节点环境上使用 1P1D 以获得更好性能的部署指南。"

#: ../../source/tutorials/DeepSeek-V3.2.md:133
msgid "Before you start, please"
msgstr "在开始之前，请"

#: ../../source/tutorials/DeepSeek-V3.2.md:134
msgid "prepare the script `launch_online_dp.py` on each node."
msgstr "在每个节点上准备脚本 `launch_online_dp.py`。"

#: ../../source/tutorials/DeepSeek-V3.2.md:237
msgid "prepare the script `run_dp_template.sh` on each node."
msgstr "在每个节点上准备脚本 `run_dp_template.sh`。"

#: ../../source/tutorials/DeepSeek-V3.2.md:239
#: ../../source/tutorials/DeepSeek-V3.2.md:547
msgid "Prefill node 0"
msgstr "预填充节点 0"

#: ../../source/tutorials/DeepSeek-V3.2.md:313
#: ../../source/tutorials/DeepSeek-V3.2.md:554
msgid "Prefill node 1"
msgstr "预填充节点 1"

#: ../../source/tutorials/DeepSeek-V3.2.md:387
#: ../../source/tutorials/DeepSeek-V3.2.md:561
msgid "Decode node 0"
msgstr "解码节点 0"

#: ../../source/tutorials/DeepSeek-V3.2.md:466
#: ../../source/tutorials/DeepSeek-V3.2.md:568
msgid "Decode node 1"
msgstr "解码节点 1"

#: ../../source/tutorials/DeepSeek-V3.2.md:545
msgid ""
"Once the preparation is done, you can start the server with the following"
" command on each node:"
msgstr "准备工作完成后，您可以在每个节点上使用以下命令启动服务器："

#: ../../source/tutorials/DeepSeek-V3.2.md:575
msgid "Functional Verification"
msgstr "功能验证"

#: ../../source/tutorials/DeepSeek-V3.2.md:577
msgid "Once your server is started, you can query the model with input prompts:"
msgstr "一旦您的服务器启动，您就可以使用输入提示词查询模型："

#: ../../source/tutorials/DeepSeek-V3.2.md:590
msgid "Accuracy Evaluation"
msgstr "精度评估"

#: ../../source/tutorials/DeepSeek-V3.2.md:592
msgid "Here are two accuracy evaluation methods."
msgstr "这里有两种精度评估方法。"

#: ../../source/tutorials/DeepSeek-V3.2.md:594
#: ../../source/tutorials/DeepSeek-V3.2.md:620
msgid "Using AISBench"
msgstr "使用 AISBench"

#: ../../source/tutorials/DeepSeek-V3.2.md:596
msgid ""
"Refer to [Using "
"AISBench](../developer_guide/evaluation/using_ais_bench.md) for details."
msgstr "详情请参考[使用 AISBench](../developer_guide/evaluation/using_ais_bench.md)。"

#: ../../source/tutorials/DeepSeek-V3.2.md:598
#: ../../source/tutorials/DeepSeek-V3.2.md:616
msgid "After execution, you can get the result."
msgstr "执行后，您可以得到结果。"

#: ../../source/tutorials/DeepSeek-V3.2.md:600
msgid "Using Language Model Evaluation Harness"
msgstr "使用 Language Model Evaluation Harness"

#: ../../source/tutorials/DeepSeek-V3.2.md:602
msgid ""
"As an example, take the `gsm8k` dataset as a test dataset, and run "
"accuracy evaluation of `DeepSeek-V3.2-W8A8` in online mode."
msgstr "以 `gsm8k` 数据集作为测试数据集为例，在线模式下运行 `DeepSeek-V3.2-W8A8` 的精度评估。"

#: ../../source/tutorials/DeepSeek-V3.2.md:604
msgid ""
"Refer to [Using lm_eval](../developer_guide/evaluation/using_lm_eval.md) "
"for `lm_eval` installation."
msgstr ""
"`lm_eval` 安装请参考[使用 "
"lm_eval](../developer_guide/evaluation/using_lm_eval.md)。"

#: ../../source/tutorials/DeepSeek-V3.2.md:606
msgid "Run `lm_eval` to execute the accuracy evaluation."
msgstr "运行 `lm_eval` 执行精度评估。"

#: ../../source/tutorials/DeepSeek-V3.2.md:618
msgid "Performance"
msgstr "性能"

#: ../../source/tutorials/DeepSeek-V3.2.md:622
msgid ""
"Refer to [Using AISBench for performance "
"evaluation](../developer_guide/evaluation/using_ais_bench.md#execute-"
"performance-evaluation) for details."
msgstr ""
"详情请参考[使用 AISBench "
"进行性能评估](../developer_guide/evaluation/using_ais_bench.md#execute-"
"performance-evaluation)。"

#: ../../source/tutorials/DeepSeek-V3.2.md:624
msgid "The performance result is:"
msgstr "性能结果如下："

#: ../../source/tutorials/DeepSeek-V3.2.md:626
msgid "**Hardware**: A3-752T, 4 node"
msgstr "**硬件**：A3-752T，4 节点"

#: ../../source/tutorials/DeepSeek-V3.2.md:628
msgid "**Deployment**: 1P1D, Prefill node: DP2+TP16, Decode Node: DP8+TP4"
msgstr "**部署**：1P1D，预填充节点：DP2+TP16，解码节点：DP8+TP4"

#: ../../source/tutorials/DeepSeek-V3.2.md:630
msgid "**Input/Output**: 64k/3k"
msgstr "**输入/输出**：64k/3k"

#: ../../source/tutorials/DeepSeek-V3.2.md:632
msgid "**Performance**: 533tps, TPOT 32ms"
msgstr "**性能**：533tps，TPOT 32ms"

#: ../../source/tutorials/DeepSeek-V3.2.md:634
msgid "Using vLLM Benchmark"
msgstr "使用 vLLM Benchmark"

#: ../../source/tutorials/DeepSeek-V3.2.md:636
msgid "Run performance evaluation of `DeepSeek-V3.2-W8A8` as an example."
msgstr "以 `DeepSeek-V3.2-W8A8` 为例运行性能评估。"

#: ../../source/tutorials/DeepSeek-V3.2.md:638
msgid ""
"Refer to [vllm "
"benchmark](https://docs.vllm.ai/en/latest/contributing/benchmarks.html) "
"for more details."
msgstr ""
"更多详情请参考 [vllm "
"benchmark](https://docs.vllm.ai/en/latest/contributing/benchmarks.html)。"

#: ../../source/tutorials/DeepSeek-V3.2.md:640
msgid "There are three `vllm bench` subcommand:"
msgstr "`vllm bench` 有三个子命令："

#: ../../source/tutorials/DeepSeek-V3.2.md:641
msgid "`latency`: Benchmark the latency of a single batch of requests."
msgstr "`latency`: 基准测试单批次请求的延迟。"

#: ../../source/tutorials/DeepSeek-V3.2.md:642
msgid "`serve`: Benchmark the online serving throughput."
msgstr "`serve`: 基准测试在线服务吞吐量。"

#: ../../source/tutorials/DeepSeek-V3.2.md:643
msgid "`throughput`: Benchmark offline inference throughput."
msgstr "`throughput`: 基准测试离线推理吞吐量。"

#: ../../source/tutorials/DeepSeek-V3.2.md:645
msgid "Take the `serve` as an example. Run the code as follows."
msgstr "以 `serve` 为例。运行以下代码。"

#: ../../source/tutorials/DeepSeek-V3.2.md:652
msgid "Function Call"
msgstr "函数调用"

#: ../../source/tutorials/DeepSeek-V3.2.md:654
msgid ""
"The function call feature is supported from v0.13.0rc1 on. Please use the"
" latest version."
msgstr "函数调用功能从 v0.13.0rc1 开始支持。请使用最新版本。"

#: ../../source/tutorials/DeepSeek-V3.2.md:656
msgid ""
"Refer to [DeepSeek-V3.2 Usage "
"Guide](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-V3_2.html"
"#tool-calling-example) for details."
msgstr ""
"详情请参考 [DeepSeek-V3.2 "
"使用指南](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-V3_2.html"
"#tool-calling-example)。"

#~ msgid ""
#~ "We strongly recommend you to install "
#~ "triton ascend package to speed up "
#~ "the inference."
#~ msgstr "我们强烈建议您安装 triton ascend 软件包以加速推理。"

#~ msgid ""
#~ "The [Triton Ascend](https://gitee.com/ascend/triton-"
#~ "ascend) is for better performance, "
#~ "please follow the instructions below to"
#~ " install it and its dependency."
#~ msgstr ""
#~ "[Triton Ascend](https://gitee.com/ascend/triton-ascend)"
#~ " 用于提升性能，请按照以下说明安装它及其依赖项。"

#~ msgid "Install the Ascend BiSheng toolkit, execute the command:"
#~ msgstr "安装 Ascend BiSheng 工具包，执行命令："

#~ msgid "Install Triton Ascend:"
#~ msgstr "安装 Triton Ascend："

