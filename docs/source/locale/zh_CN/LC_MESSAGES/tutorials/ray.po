# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2026.
#
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-22 17:09+0800\n"
"PO-Revision-Date: 2026-01-22 18:45+0800\n"
"Last-Translator: Gemini\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/tutorials/ray.md:1
msgid "Ray Distributed (Qwen3-235B-A22B)"
msgstr "Ray分布式部署(Qwen3-235B-A22B)"

#: ../../source/tutorials/ray.md:3
msgid ""
"Multi-node inference is suitable for scenarios where the model cannot be "
"deployed on a single machine. In such cases, the model can be distributed"
" using tensor parallelism or pipeline parallelism. The specific "
"parallelism strategies will be covered in the following sections. To "
"successfully deploy multi-node inference, the following three steps need "
"to be completed:"
msgstr ""
"多节点推理适用于模型无法部署在单台机器上的场景。在这种情况下，可以使用张量并行（Tensor "
"Parallelism）或流水线并行（Pipeline "
"Parallelism）来分布式部署模型。具体的并行策略将在后续章节中介绍。要成功部署多节点推理，需要完成以下三个步骤："

#: ../../source/tutorials/ray.md:5
msgid "**Verify Multi-Node Communication Environment**"
msgstr "**验证多节点通信环境**"

#: ../../source/tutorials/ray.md:6
msgid "**Set Up and Start the Ray Cluster**"
msgstr "**搭建并启动 Ray 集群**"

#: ../../source/tutorials/ray.md:7
msgid "**Start the Online Inference Service on Multi-node**"
msgstr "**在多节点环境下启动在线推理服务**"

#: ../../source/tutorials/ray.md:9
msgid "Verify Multi-Node Communication Environment"
msgstr "验证多节点通信环境"

#: ../../source/tutorials/ray.md:11
msgid "Physical Layer Requirements:"
msgstr "物理层要求："

#: ../../source/tutorials/ray.md:13
msgid ""
"The physical machines must be located on the same LAN, with network "
"connectivity."
msgstr "物理机必须位于同一个局域网（LAN）内，且网络连通。"

#: ../../source/tutorials/ray.md:14
msgid ""
"All NPUs are connected with optical modules, and the connection status "
"must be normal."
msgstr "所有 NPU 均通过光模块连接，且连接状态必须正常。"

#: ../../source/tutorials/ray.md:16
msgid "Verification Process:"
msgstr "验证过程："

#: ../../source/tutorials/ray.md:18
msgid ""
"Execute the following commands on each node in sequence. The results must"
" all be `success` and the status must be `UP`:"
msgstr "依次在每个节点上执行以下命令。结果必须全部为 `success`，且状态必须为 `UP`："

#: ../../source/tutorials/ray.md:35
msgid "NPU Interconnect Verification:"
msgstr "NPU 互联验证："

#: ../../source/tutorials/ray.md:36
msgid "1. Get NPU IP Addresses"
msgstr "1. 获取 NPU IP 地址"

#: ../../source/tutorials/ray.md:42
msgid "2. Cross-Node PING Test"
msgstr "2. 跨节点 PING 测试"

#: ../../source/tutorials/ray.md:49
msgid "Set Up and Start the Ray Cluster"
msgstr "搭建并启动 Ray 集群"

#: ../../source/tutorials/ray.md:50
msgid "Setting Up the Basic Container"
msgstr "搭建基础容器"

#: ../../source/tutorials/ray.md:51
msgid ""
"To ensure a consistent execution environment across all nodes, including "
"the model path and Python environment, it is advised to use Docker "
"images."
msgstr "为确保所有节点的执行环境（包括模型路径和 Python 环境）一致，建议使用 Docker 镜像。"

#: ../../source/tutorials/ray.md:53
msgid ""
"For setting up a multi-node inference cluster with Ray, **containerized "
"deployment** is the preferred approach. Containers should be started on "
"both the primary and secondary nodes, with the `--net=host` option to "
"enable proper network connectivity."
msgstr ""
"对于使用 Ray 搭建的多节点推理集群，**容器化部署**是首选方法。应在主节点和从节点上同时启动容器，并使用 `--net=host` "
"选项以确保正常的网络连通性。"

#: ../../source/tutorials/ray.md:55
msgid ""
"Below is the example container setup command, which should be executed on"
" **all nodes** :"
msgstr "下面是容器设置命令示例，应在**所有节点**上执行："

#: ../../source/tutorials/ray.md:90
msgid "Start Ray Cluster"
msgstr "启动 Ray 集群"

#: ../../source/tutorials/ray.md:91
msgid ""
"After setting up the containers and installing vllm-ascend on each node, "
"follow the steps below to start the Ray cluster and execute inference "
"tasks."
msgstr "在每个节点上设置好容器并安装 vllm-ascend 后，按照以下步骤启动 Ray 集群并执行推理任务。"

#: ../../source/tutorials/ray.md:93
msgid ""
"Choose one machine as the primary node and the others as secondary nodes."
" Before proceeding, use `ip addr` to check your `nic_name` (network "
"interface name)."
msgstr ""
"选择一台机器作为主节点（Primary Node），其余机器作为从节点（Secondary Node）。在开始之前，使用 `ip addr` "
"检查您的 `nic_name`（网卡名称）。"

#: ../../source/tutorials/ray.md:95
msgid ""
"Set the `ASCEND_RT_VISIBLE_DEVICES` environment variable to specify the "
"NPU devices to use. For Ray versions above 2.1, also set the "
"`RAY_EXPERIMENTAL_NOSET_ASCEND_RT_VISIBLE_DEVICES` variable to avoid "
"device recognition issues."
msgstr ""
"设置 `ASCEND_RT_VISIBLE_DEVICES` 环境变量来指定要使用的 NPU 设备。对于 2.1 以上版本的 Ray，还需设置 "
"`RAY_EXPERIMENTAL_NOSET_ASCEND_RT_VISIBLE_DEVICES` 变量以避免设备识别问题。"

#: ../../source/tutorials/ray.md:97
msgid "Below are the commands for the primary and secondary nodes:"
msgstr "下面是主节点和从节点的执行命令："

#: ../../source/tutorials/ray.md:99
msgid "**Primary node**:"
msgstr "**主节点 (Primary node)**："

#: ../../source/tutorials/ray.md:102 ../../source/tutorials/ray.md:119
msgid ""
"When starting a Ray cluster for multi-node inference, the environment "
"variables on each node must be set **before** starting the Ray cluster "
"for them to take effect. Updating the environment variables requires "
"restarting the Ray cluster."
msgstr "启动用于多节点推理的 Ray 集群时，各节点的环境变量必须在启动 Ray 集群**之前**设置才能生效。更新环境变量需要重启 Ray 集群。"

#: ../../source/tutorials/ray.md:116
msgid "**Secondary node**:"
msgstr "**从节点 (Secondary node)**："

#: ../../source/tutorials/ray.md:132
msgid ""
"Once the cluster is started on multiple nodes, execute `ray status` and "
"`ray list nodes` to verify the Ray cluster's status. You should see the "
"correct number of nodes and NPUs listed."
msgstr ""
"多节点集群启动后，执行 `ray status` 和 `ray list nodes` 验证 Ray 集群状态。您应该能看到正确的节点数量和 "
"NPU 列表。"

#: ../../source/tutorials/ray.md:134
msgid ""
"After Ray is successfully started, the following content will appear:\\ A"
" local Ray instance has started successfully.\\ Dashboard URL: The access"
" address for the Ray Dashboard (default: http://localhost:8265); Node "
"status (CPU/memory resources, number of healthy nodes); Cluster "
"connection address (used for adding multiple nodes)."
msgstr ""
"Ray 成功启动后，将出现以下内容：本地 Ray 实例已成功启动；Dashboard URL：Ray "
"仪表板的访问地址（默认：http://localhost:8265）；节点状态（CPU/内存资源、健康节点数量）；集群连接地址（用于添加多个节点）。"

#: ../../source/tutorials/ray.md:138
msgid "Start the Online Inference Service on Multi-node scenario"
msgstr "在多节点场景下启动在线推理服务"

#: ../../source/tutorials/ray.md:139
msgid ""
"In the container, you can use vLLM as if all NPUs were on a single node. "
"vLLM will utilize NPU resources across all nodes in the Ray cluster."
msgstr "在容器中，您可以像所有 NPU 都在单个节点上一样使用 vLLM。vLLM 将利用 Ray 集群中所有节点的 NPU 资源。"

#: ../../source/tutorials/ray.md:141
msgid "**You only need to run the vllm command on one node.**"
msgstr "**您只需要在一个节点上运行 vllm 命令。**"

#: ../../source/tutorials/ray.md:143
msgid ""
"To set up parallelism, the common practice is to set the `tensor-"
"parallel-size` to the number of NPUs per node, and the `pipeline-"
"parallel-size` to the number of nodes."
msgstr ""
"要设置并行度，通常的做法是将 `tensor-parallel-size` 设置为每个节点的 NPU 数量，并将 `pipeline-"
"parallel-size` 设置为节点数量。"

#: ../../source/tutorials/ray.md:145
msgid ""
"For example, with 16 NPUs across 2 nodes (8 NPUs per node), set the "
"tensor parallel size to 8 and the pipeline parallel size to 2:"
msgstr "例如，跨 2 个节点共有 16 个 NPU（每节点 8 个 NPU），则将张量并行大小设置为 8，流水线并行大小设置为 2："

#: ../../source/tutorials/ray.md:161
msgid ""
"Alternatively, if you want to use only tensor parallelism, set the tensor"
" parallel size to the total number of NPUs in the cluster. For example, "
"with 16 NPUs across 2 nodes, set the tensor parallel size to 16:"
msgstr ""
"或者，如果您只想使用张量并行，请将张量并行大小设置为集群中的 NPU 总数。例如，跨 2 个节点共有 16 个 NPU，则将张量并行大小设置为 "
"16："

#: ../../source/tutorials/ray.md:176
msgid "Once your server is started, you can query the model with input prompts:"
msgstr "服务器启动后，您可以使用输入提示词查询模型："

