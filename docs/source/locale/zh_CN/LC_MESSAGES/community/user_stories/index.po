# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version:  vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-21 10:23+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/community/user_stories/index.md:15
msgid "More details"
msgstr "更多详情"

#: ../../source/community/user_stories/index.md:1
msgid "User Stories"
msgstr "用户案例"

#: ../../source/community/user_stories/index.md:3
msgid ""
"Read case studies on how users and developers solve real, everyday "
"problems with vLLM Ascend"
msgstr "阅读案例研究，了解用户和开发者如何使用 vLLM Ascend 解决实际日常问题。"

#: ../../source/community/user_stories/index.md:5
msgid ""
"[LLaMA-Factory](./llamafactory.md) is an easy-to-use and efficient "
"platform for training and fine-tuning large language models. It supports "
"vLLM Ascend to speed up inference since [LLaMA-"
"Factory#7739](https://github.com/hiyouga/LLaMA-Factory/pull/7739), "
"gaining 2x performance enhancement in inference."
msgstr ""
"[LLaMA-Factory](./llamafactory.md) 是一个易于使用且高效的大语言模型训练与微调平台。自 [LLaMA-"
"Factory#7739](https://github.com/hiyouga/LLaMA-Factory/pull/7739) 起支持 "
"vLLM Ascend 以加速推理，推理性能提升达 2 倍。"

#: ../../source/community/user_stories/index.md:7
msgid ""
"[Huggingface/trl](https://github.com/huggingface/trl) is a cutting-edge "
"library designed for post-training foundation models using advanced "
"techniques like SFT, PPO and DPO. It uses vLLM Ascend since "
"[v0.17.0](https://github.com/huggingface/trl/releases/tag/v0.17.0) to "
"support RLHF on Ascend NPUs."
msgstr ""
"[Huggingface/trl](https://github.com/huggingface/trl) 是一个前沿库，专为使用 SFT、PPO 和 DPO "
"等先进技术对基础模型进行后训练而设计。自 "
"[v0.17.0](https://github.com/huggingface/trl/releases/tag/v0.17.0) 版本起集成 vLLM Ascend，以支持在昇腾 NPU 上进行 RLHF。"

#: ../../source/community/user_stories/index.md:9
msgid ""
"[MindIE Turbo](https://pypi.org/project/mindie-turbo) is an LLM inference"
" engine acceleration plugin library developed by Huawei on Ascend "
"hardware, which includes self-developed LLM optimization algorithms and "
"optimizations related to the inference engine framework. It supports vLLM"
" Ascend since "
"[2.0rc1](https://www.hiascend.com/document/detail/zh/mindie/20RC1/AcceleratePlugin/turbodev"
"/mindie-turbo-0001.html)."
msgstr ""
"[MindIE Turbo](https://pypi.org/project/mindie-turbo) 是华为基于昇腾硬件开发的 LLM "
"推理引擎加速插件库，包含自研的大语言模型优化算法以及与推理引擎框架相关的优化。自 "
"[2.0rc1](https://www.hiascend.com/document/detail/zh/mindie/20RC1/AcceleratePlugin/turbodev/mindie-turbo-0001.html) 版本起支持 vLLM Ascend。"

#: ../../source/community/user_stories/index.md:11
msgid ""
"[GPUStack](https://github.com/gpustack/gpustack) is an open-source GPU "
"cluster manager for running AI models. It supports vLLM Ascend since "
"[v0.6.2](https://github.com/gpustack/gpustack/releases/tag/v0.6.2). See "
"more GPUStack performance evaluation information at [this "
"link](https://mp.weixin.qq.com/s/pkytJVjcH9_OnffnsFGaew)."
msgstr ""
"[GPUStack](https://github.com/gpustack/gpustack) 是一个用于运行 AI 模型的开源 GPU "
"集群管理器。自 [v0.6.2](https://github.com/gpustack/gpustack/releases/tag/v0.6.2) "
"版本起支持 vLLM Ascend。更多 GPUStack 性能评测信息，请参阅[此链接](https://mp.weixin.qq.com/s/pkytJVjcH9_OnffnsFGaew)。"

#: ../../source/community/user_stories/index.md:13
msgid ""
"[verl](https://github.com/volcengine/verl) is a flexible, efficient, and "
"production-ready RL training library for LLMs. It uses vLLM Ascend since "
"[v0.4.0](https://github.com/volcengine/verl/releases/tag/v0.4.0). See "
"more information on [verl x Ascend "
"Quickstart](https://verl.readthedocs.io/en/latest/ascend_tutorial/ascend_quick_start.html)."
msgstr ""
"[verl](https://github.com/volcengine/verl) 是一个灵活、高效且可用于生产环境的 LLM 强化学习训练库。自 "
"[v0.4.0](https://github.com/volcengine/verl/releases/tag/v0.4.0) 版本起集成 vLLM "
"Ascend。更多信息，请参阅 [verl x Ascend 快速入门](https://verl.readthedocs.io/en/latest/ascend_tutorial/ascend_quick_start.html)。"

