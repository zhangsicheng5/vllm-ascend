# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version:  vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-21 10:23+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:1
msgid "Performance Benchmark"
msgstr "æ€§èƒ½åŸºå‡†æµ‹è¯•"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:2
msgid ""
"This document details the benchmark methodology for vllm-ascend, aimed at"
" evaluating the performance under a variety of workloads. To maintain "
"alignment with vLLM, we use the [benchmark](https://github.com/vllm-"
"project/vllm/tree/main/benchmarks) script provided by the vllm project."
msgstr "æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº† vllm-ascend çš„åŸºå‡†æµ‹è¯•æ–¹æ³•ï¼Œæ—¨åœ¨è¯„ä¼°å…¶åœ¨å¤šç§å·¥ä½œè´Ÿè½½ä¸‹çš„æ€§èƒ½ã€‚ä¸ºä¸ vLLM ä¿æŒä¸€è‡´ï¼Œæˆ‘ä»¬ä½¿ç”¨ vllm é¡¹ç›®æä¾›çš„ [benchmark](https://github.com/vllm-project/vllm/tree/main/benchmarks) è„šæœ¬ã€‚"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:4
msgid ""
"**Benchmark Coverage**: We measure offline E2E latency and throughput, "
"and fixed-QPS online serving benchmarks. For more details, see [vllm-"
"ascend benchmark scripts](https://github.com/vllm-project/vllm-"
"ascend/tree/main/benchmarks)."
msgstr "**åŸºå‡†æµ‹è¯•è¦†ç›–èŒƒå›´**ï¼šæˆ‘ä»¬æµ‹é‡ç¦»çº¿ç«¯åˆ°ç«¯å»¶è¿Ÿä¸ååé‡ï¼Œä»¥åŠå›ºå®š QPS çš„åœ¨çº¿æœåŠ¡åŸºå‡†æµ‹è¯•ã€‚æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜… [vllm-ascend åŸºå‡†æµ‹è¯•è„šæœ¬](https://github.com/vllm-project/vllm-ascend/tree/main/benchmarks)ã€‚"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:6
msgid "1. Run docker container"
msgstr "1.è¿è¡Œ Docker å®¹å™¨"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:32
msgid "2. Install dependencies"
msgstr "2.å®‰è£…ä¾èµ–é¡¹"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:40
msgid "3. Run basic benchmarks"
msgstr "3.è¿è¡ŒåŸºç¡€åŸºå‡†æµ‹è¯•"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:41
msgid ""
"This section introduces how to perform performance testing using the "
"benchmark suite built into VLLM."
msgstr "æœ¬èŠ‚ä»‹ç»å¦‚ä½•ä½¿ç”¨ VLLM å†…ç½®çš„åŸºå‡†æµ‹è¯•å¥—ä»¶è¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:43
msgid "3.1 Dataset"
msgstr "3.1æ•°æ®é›†"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:44
msgid ""
"VLLM supports a variety of (datasets)[https://github.com/vllm-"
"project/vllm/blob/main/vllm/benchmarks/datasets.py]."
msgstr "VLLM æ”¯æŒå¤šç§[æ•°æ®é›†](https://github.com/vllm-project/vllm/blob/main/vllm/benchmarks/datasets.py)ã€‚"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Dataset"
msgstr "æ•°æ®é›†"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Online"
msgstr "åœ¨çº¿"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Offline"
msgstr "ç¦»çº¿"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Data Path"
msgstr "æ•°æ®è·¯å¾„"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "ShareGPT"
msgstr "ShareGPT"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "âœ…"
msgstr "âœ…"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid ""
"`wget "
"https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json`"
msgstr "`wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "ShareGPT4V (Image)"
msgstr "ShareGPT4Vï¼ˆå›¾åƒï¼‰"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid ""
"`wget https://huggingface.co/datasets/Lin-"
"Chen/ShareGPT4V/resolve/main/sharegpt4v_instruct_gpt4-vision_cap100k.json`<br>Note"
" that the images need to be downloaded separately. For example, to "
"download COCO's 2017 Train images:<br>`wget "
"http://images.cocodataset.org/zips/train2017.zip`"
msgstr ""
"`wget https://huggingface.co/datasets/Lin-Chen/ShareGPT4V/resolve/main/sharegpt4v_instruct_gpt4-vision_cap100k.json`<br>æ³¨æ„ï¼šå›¾åƒéœ€è¦å•ç‹¬ä¸‹è½½ã€‚ä¾‹å¦‚ï¼Œè¦ä¸‹è½½ COCO 2017 è®­ç»ƒå›¾åƒï¼š<br>`wget "
"http://images.cocodataset.org/zips/train2017.zip`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "ShareGPT4Video (Video)"
msgstr "ShareGPT4Videoï¼ˆè§†é¢‘ï¼‰"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`git clone https://huggingface.co/datasets/ShareGPT4Video/ShareGPT4Video`"
msgstr "`git clone https://huggingface.co/datasets/ShareGPT4Video/ShareGPT4Video`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "BurstGPT"
msgstr "BurstGPT"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid ""
"`wget "
"https://github.com/HPMLL/BurstGPT/releases/download/v1.1/BurstGPT_without_fails_2.csv`"
msgstr "`wget https://github.com/HPMLL/BurstGPT/releases/download/v1.1/BurstGPT_without_fails_2.csv`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Sonnet (deprecated)"
msgstr "Sonnetï¼ˆå·²å¼ƒç”¨ï¼‰"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Local file: `benchmarks/sonnet.txt`"
msgstr "æœ¬åœ°æ–‡ä»¶ï¼š`benchmarks/sonnet.txt`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Random"
msgstr "éšæœº"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`synthetic`"
msgstr "`synthetic`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "RandomMultiModal (Image/Video)"
msgstr "éšæœºå¤šæ¨¡æ€ï¼ˆå›¾åƒ/è§†é¢‘ï¼‰"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "ğŸŸ¡"
msgstr "ğŸŸ¡"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "ğŸš§"
msgstr "ğŸš§"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "RandomForReranking"
msgstr "éšæœºé‡æ’åº"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Prefix Repetition"
msgstr "å‰ç¼€é‡å¤"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-VisionArena"
msgstr "HuggingFace-VisionArena"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`lmarena-ai/VisionArena-Chat`"
msgstr "`lmarena-ai/VisionArena-Chat`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-MMVU"
msgstr "HuggingFace-MMVU"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`yale-nlp/MMVU`"
msgstr "`yale-nlp/MMVU`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-InstructCoder"
msgstr "HuggingFace-InstructCoder"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`likaixin/InstructCoder`"
msgstr "`likaixin/InstructCoder`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-AIMO"
msgstr "HuggingFace-AIMO"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid ""
"`AI-MO/aimo-validation-aime`, `AI-MO/NuminaMath-1.5`, `AI-MO/NuminaMath-"
"CoT`"
msgstr "`AI-MO/aimo-validation-aime`, `AI-MO/NuminaMath-1.5`, `AI-MO/NuminaMath-CoT`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-Other"
msgstr "HuggingFace-å…¶ä»–"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`lmms-lab/LLaVA-OneVision-Data`, `Aeala/ShareGPT_Vicuna_unfiltered`"
msgstr "`lmms-lab/LLaVA-OneVision-Data`, `Aeala/ShareGPT_Vicuna_unfiltered`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-MTBench"
msgstr "HuggingFace-MTBench"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`philschmid/mt-bench`"
msgstr "`philschmid/mt-bench`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "HuggingFace-Blazedit"
msgstr "HuggingFace-Blazedit"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "`vdaita/edit_5k_char`, `vdaita/edit_10k_char`"
msgstr "`vdaita/edit_5k_char`, `vdaita/edit_10k_char`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Spec Bench"
msgstr "Spec Bench"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid ""
"`wget https://raw.githubusercontent.com/hemingkx/Spec-"
"Bench/refs/heads/main/data/spec_bench/question.jsonl`"
msgstr "`wget https://raw.githubusercontent.com/hemingkx/Spec-Bench/refs/heads/main/data/spec_bench/question.jsonl`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Custom"
msgstr "è‡ªå®šä¹‰"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:8
msgid "Local file: `data.jsonl`"
msgstr "æœ¬åœ°æ–‡ä»¶ï¼š`data.jsonl`"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:74
msgid ""
"The datasets mentioned above are all links to datasets on huggingface. "
"The dataset's `dataset-name` should be set to `hf`. For local `dataset-"
"path`, please set `hf-name` to its Hugging Face ID like"
msgstr "ä¸Šè¿°æ•°æ®é›†å‡ä¸º Hugging Face ä¸Šæ•°æ®é›†çš„é“¾æ¥ã€‚æ•°æ®é›†çš„ `dataset-name` åº”è®¾ç½®ä¸º `hf`ã€‚å¯¹äºæœ¬åœ°çš„ `dataset-path`ï¼Œè¯·å°†å…¶ `hf-name` è®¾ç½®ä¸ºå¯¹åº”çš„ Hugging Face IDï¼Œä¾‹å¦‚ï¼š"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:84
msgid "3.2 Run basic benchmark"
msgstr "3.2è¿è¡ŒåŸºç¡€åŸºå‡†æµ‹è¯•"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:86
msgid "3.2.1 Online serving"
msgstr "3.2.1åœ¨çº¿æœåŠ¡"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:88
msgid "First start serving your model:"
msgstr "é¦–å…ˆå¯åŠ¨æ¨¡å‹æœåŠ¡ï¼š"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:94
msgid "Then run the benchmarking script:"
msgstr "ç„¶åè¿è¡ŒåŸºå‡†æµ‹è¯•è„šæœ¬ï¼š"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:109
msgid "If successful, you will see the following output:"
msgstr "å¦‚æœæˆåŠŸï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:138
msgid "3.2.2 Offline Throughput Benchmark"
msgstr "3.2.2ç¦»çº¿ååé‡åŸºå‡†æµ‹è¯•"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:149
msgid "If successful, you will see the following output"
msgstr "å¦‚æœæˆåŠŸï¼Œæ‚¨å°†çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:158
msgid "3.2.4 Multi-Modal Benchmark"
msgstr "3.2.4å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•"

#: ../../source/developer_guide/performance_and_debug/performance_benchmark.md:207
msgid "3.2.5 Embedding Benchmark"
msgstr "3.2.5åµŒå…¥åŸºå‡†æµ‹è¯•"

#~ msgid "3. (Optional)Prepare model weights"
#~ msgstr "3.ï¼ˆå¯é€‰ï¼‰å‡†å¤‡æ¨¡å‹æƒé‡"

#~ msgid ""
#~ "For faster running speed, we recommend"
#~ " downloading the model in advanceï¼š"
#~ msgstr "ä¸ºè·å¾—æ›´å¿«çš„è¿è¡Œé€Ÿåº¦ï¼Œå»ºè®®æå‰ä¸‹è½½æ¨¡å‹ï¼š"

#~ msgid ""
#~ "You can also replace all model "
#~ "paths in the [json](https://github.com/vllm-"
#~ "project/vllm-ascend/tree/main/benchmarks/tests) files "
#~ "with your local paths:"
#~ msgstr "æ‚¨ä¹Ÿå¯ä»¥å°† [json](https://github.com/vllm-project/vllm-ascend/tree/main/benchmarks/tests) æ–‡ä»¶ä¸­çš„æ‰€æœ‰æ¨¡å‹è·¯å¾„æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„ï¼š"

#~ msgid "After about 10 mins, the output is as shown below:"
#~ msgstr "å¤§çº¦ 10 åˆ†é’Ÿåï¼Œè¾“å‡ºå¦‚ä¸‹æ‰€ç¤ºï¼š"

#~ msgid ""
#~ "The result json files are generated "
#~ "into the path `benchmark/results` These "
#~ "files contain detailed benchmarking results"
#~ " for further analysis."
#~ msgstr "ç»“æœ JSON æ–‡ä»¶å°†ç”Ÿæˆåˆ° `benchmark/results` è·¯å¾„ä¸‹ã€‚è¿™äº›æ–‡ä»¶åŒ…å«è¯¦ç»†çš„åŸºå‡†æµ‹è¯•ç»“æœï¼Œå¯ç”¨äºè¿›ä¸€æ­¥åˆ†æã€‚"