# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version:  vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-21 10:23+0800\n"
"PO-Revision-Date: 2025-07-18 10:09+0800\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/installation.md:1
msgid "Installation"
msgstr "安装"

#: ../../source/installation.md:3
msgid "This document describes how to install vllm-ascend manually."
msgstr "本文档介绍了如何手动安装 vllm-ascend。"

#: ../../source/installation.md:5
msgid "Requirements"
msgstr "要求"

#: ../../source/installation.md:7
msgid "OS: Linux"
msgstr "操作系统：Linux"

#: ../../source/installation.md:8
msgid "Python: >= 3.10, < 3.12"
msgstr "Python：>= 3.10, < 3.12"

#: ../../source/installation.md:9
msgid "A hardware with Ascend NPU. It's usually the Atlas 800 A2 series."
msgstr "配备昇腾 NPU 的硬件设备，通常为 Atlas 800 A2 系列。"

#: ../../source/installation.md:10
msgid "Software:"
msgstr "软件："

#: ../../source/installation.md
msgid "Software"
msgstr "软件"

#: ../../source/installation.md
msgid "Supported version"
msgstr "支持的版本"

#: ../../source/installation.md
msgid "Note"
msgstr "说明"

#: ../../source/installation.md
msgid "Ascend HDK"
msgstr "Ascend HDK"

#: ../../source/installation.md
msgid ""
"Refer to "
"[here](https://www.hiascend.com/document/detail/zh/canncommercial/83RC1/releasenote/releasenote_0000.html)"
msgstr "参考[此处](https://www.hiascend.com/document/detail/zh/canncommercial/83RC1/releasenote/releasenote_0000.html)"

#: ../../source/installation.md
msgid "Required for CANN"
msgstr "CANN 运行必需"

#: ../../source/installation.md
msgid "CANN"
msgstr "CANN"

#: ../../source/installation.md
msgid "== 8.3.RC2"
msgstr "== 8.3.RC2"

#: ../../source/installation.md
msgid "Required for vllm-ascend and torch-npu"
msgstr "vllm-ascend 和 torch-npu 运行必需"

#: ../../source/installation.md
msgid "torch-npu"
msgstr "torch-npu"

#: ../../source/installation.md
msgid "== 2.8.0"
msgstr "== 2.8.0"

#: ../../source/installation.md
msgid ""
"Required for vllm-ascend, No need to install manually, it will be auto "
"installed in below steps"
msgstr "vllm-ascend 必需，无需手动安装，后续步骤会自动安装。"

#: ../../source/installation.md
msgid "torch"
msgstr "torch"

#: ../../source/installation.md
msgid "Required for torch-npu and vllm"
msgstr "torch-npu 和 vllm 运行必需"

#: ../../source/installation.md
msgid "NNAL"
msgstr "NNAL"

#: ../../source/installation.md
msgid "Required for libatb.so, enables advanced tensor operations"
msgstr "libatb.so 必需，用于启用高级张量算子加速"

#: ../../source/installation.md:20
msgid "There are two installation methods:"
msgstr "有两种安装方式："

#: ../../source/installation.md:21
msgid ""
"**Using pip**: first prepare env manually or via CANN image, then install"
" `vllm-ascend` using pip."
msgstr "**使用 pip**：首先手动或通过 CANN 镜像准备环境，然后使用 pip 安装 `vllm-ascend`。"

#: ../../source/installation.md:22
msgid "**Using docker**: use the `vllm-ascend` pre-built docker image directly."
msgstr "**使用 Docker**：直接使用 `vllm-ascend` 预构建的 Docker 镜像。"

#: ../../source/installation.md:24
msgid "Configure Ascend CANN environment"
msgstr "配置昇腾 CANN 环境"

#: ../../source/installation.md:26
msgid ""
"Before installation, you need to make sure firmware/driver and CANN are "
"installed correctly, refer to [Ascend Environment Setup "
"Guide](https://ascend.github.io/docs/sources/ascend/quick_install.html) "
"for more details."
msgstr ""
"在安装之前，请确保固件/驱动和 CANN 已正确安装，更多详情请参考 "
"[昇腾环境搭建指南](https://ascend.github.io/docs/sources/ascend/quick_install.html)。"

#: ../../source/installation.md:28
msgid "Configure hardware environment"
msgstr "配置硬件环境"

#: ../../source/installation.md:30
msgid ""
"To verify that the Ascend NPU firmware and driver were correctly "
"installed, run:"
msgstr "要验证 Ascend NPU 固件和驱动程序是否正确安装，请运行："

#: ../../source/installation.md:36
msgid ""
"Refer to [Ascend Environment Setup "
"Guide](https://ascend.github.io/docs/sources/ascend/quick_install.html) "
"for more details."
msgstr "更多详情请参考[Ascend环境搭建指南](https://ascend.github.io/docs/sources/ascend/quick_install.html)。"

#: ../../source/installation.md:38
msgid "Configure software environment"
msgstr "配置软件环境"

#: ../../source/installation.md
msgid "Before using pip"
msgstr "在使用 pip 之前"

#: ../../source/installation.md:48
msgid ""
"The easiest way to prepare your software environment is using CANN image "
"directly:"
msgstr "准备软件环境最简单的方法是直接使用 CANN 官方镜像："

#: ../../source/installation.md:51
msgid ""
"The CANN prebuilt image includes NNAL (Ascend Neural Network Acceleration"
" Library) which provides libatb.so for advanced tensor operations. No "
"additional installation is required when using the prebuilt image."
msgstr ""
"CANN 预构建镜像已包含 NNAL（昇腾神经网络加速库），它为高级张量操作提供 libatb.so 支持。使用预构建镜像时无需额外安装。"

#: ../../source/installation.md
msgid "Click here to see \"Install CANN manually\""
msgstr "点击此处查看“手动安装 CANN”"

#: ../../source/installation.md:79
msgid "You can also install CANN manually:"
msgstr "您也可以选择手动安装 CANN："

#: ../../source/installation.md:82
msgid ""
"If you encounter \"libatb.so not found\" errors during runtime, please "
"ensure NNAL is properly installed as shown in the manual installation "
"steps below."
msgstr ""
"如果在运行时遇到 “libatb.so not found” 错误，请确保已按照下文的手动安装步骤正确安装了 NNAL。"

#: ../../source/installation.md
msgid "Before using docker"
msgstr "在使用 Docker 之前"

#: ../../source/installation.md:115
msgid "No more extra step if you are using `vllm-ascend` prebuilt Docker image."
msgstr "如果您使用的是 `vllm-ascend` 预构建的 Docker 镜像，则无需额外步骤。"

#: ../../source/installation.md:119
msgid "Once it is done, you can start to set up `vllm` and `vllm-ascend`."
msgstr "完成上述步骤后，即可开始安装 `vllm` 和 `vllm-ascend`。"

#: ../../source/installation.md:121
msgid "Set up using Python"
msgstr "使用 Python 安装"

#: ../../source/installation.md:123
msgid "First install system dependencies and configure pip mirror:"
msgstr "首先安装系统依赖并配置 pip 镜像源："

#: ../../source/installation.md:135
msgid ""
"**[Optional]** Then configure the extra-index of `pip` if you are working"
" on an x86 machine or using torch-npu dev version:"
msgstr "**[可选]** 如果您在 x86 架构机器上操作或使用 torch-npu 开发版本，请配置 pip 的额外索引 (extra-index)："

#: ../../source/installation.md:142
msgid "Then you can install `vllm` and `vllm-ascend` from **pre-built wheel**:"
msgstr "接着，您可以从**预构建的 wheel 包**安装 `vllm` 和 `vllm-ascend`："

#: ../../source/installation.md
msgid "Click here to see \"Build from source code\""
msgstr "点击此处查看“从源代码构建”"

#: ../../source/installation.md:155
msgid "or build from **source code**:"
msgstr "或者从**源代码**构建："

#: ../../source/installation.md:174
msgid ""
"If you are building custom operators for Atlas A3, you should run `git "
"submodule update --init --recursive` manually, or ensure your environment"
" has Internet access."
msgstr ""
"如果您正在为 Atlas A3 构建自定义算子，请手动执行 `git submodule update --init --recursive`，或确保您的环境可以访问互联网。"

#: ../../source/installation.md:178
msgid ""
"To build custom operators, gcc/g++ higher than 8 and c++ 17 or higher is "
"required. If you're using `pip install -e .` and encounter a torch-npu "
"version conflict, please install with `pip install --no-build-isolation "
"-e .` to build on system env. If you encounter other problems during "
"compiling, it is probably because unexpected compiler is being used, you "
"may export `CXX_COMPILER` and `C_COMPILER` in environment to specify your"
" g++ and gcc locations before compiling."
msgstr ""
"构建自定义算子需要 gcc/g++ 版本高于 8 且支持 C++17 或更高标准。如果您在使用 `pip install -e .` 时遇到 torch-npu 版本冲突，请使用 `pip install --no-build-isolation -e .` 以在系统环境下构建。如果在编译过程中遇到其他问题，通常是因为使用了非预期的编译器，您可以在编译前导出 `CXX_COMPILER` 和 `C_COMPILER` 环境变量来指定 g++ 和 gcc 的具体路径。"

#: ../../source/installation.md:182
msgid "Set up using Docker"
msgstr "使用 Docker 安装"

#: ../../source/installation.md:184
msgid ""
"`vllm-ascend` offers Docker images for deployment. You can just pull the "
"**prebuilt image** from the image repository [ascend/vllm-"
"ascend](https://quay.io/repository/ascend/vllm-ascend?tab=tags) and run "
"it with bash."
msgstr ""
"`vllm-ascend` 提供了用于部署的 Docker 镜像。您可以直接从镜像仓库 [ascend/vllm-ascend](https://quay.io/repository/ascend/vllm-ascend?tab=tags) 拉取**预构建镜像**并运行。"

#: ../../source/installation.md:186
msgid "Supported images as following."
msgstr "支持的镜像如下："

#: ../../source/installation.md:177
msgid "image name"
msgstr "镜像名称"

#: ../../source/installation.md:177
msgid "Hardware"
msgstr "硬件"

#: ../../source/installation.md:177
msgid "OS"
msgstr "操作系统"

#: ../../source/installation.md:177
msgid "image-tag"
msgstr "镜像标签"

#: ../../source/installation.md:177
msgid "Atlas A2"
msgstr "Atlas A2"

#: ../../source/installation.md:177
msgid "Ubuntu"
msgstr "Ubuntu"

#: ../../source/installation.md:177
msgid "image-tag-openeuler"
msgstr "image-tag-openeuler"

#: ../../source/installation.md:177
msgid "openEuler"
msgstr "openEuler"

#: ../../source/installation.md:177
msgid "image-tag-a3"
msgstr "image-tag-a3"

#: ../../source/installation.md:177
msgid "Atlas A3"
msgstr "Atlas A3"

#: ../../source/installation.md:177
msgid "image-tag-a3-openeuler"
msgstr "image-tag-a3-openeuler"

#: ../../source/installation.md:177
msgid "image-tag-310p"
msgstr "image-tag-310p"

#: ../../source/installation.md:177
msgid "Atlas 300I"
msgstr "Atlas 300I"

#: ../../source/installation.md:177
msgid "image-tag-310p-openeuler"
msgstr "image-tag-310p-openeuler"

#: ../../source/installation.md
msgid "Click here to see \"Build from Dockerfile\""
msgstr "点击此处查看“从 Dockerfile 构建”"

#: ../../source/installation.md:197
msgid "or build IMAGE from **source code**:"
msgstr "或者从**源代码**构建镜像："

#: ../../source/installation.md:239
msgid ""
"The default workdir is `/workspace`, vLLM and vLLM Ascend code are placed"
" in `/vllm-workspace` and installed in [development "
"mode](https://setuptools.pypa.io/en/latest/userguide/development_mode.html)"
" (`pip install -e`) to help developer immediately take place changes "
"without requiring a new installation."
msgstr ""
"默认工作目录为 `/workspace`，vLLM 和 vLLM Ascend 源码位于 `/vllm-workspace`，并以[开发模式](https://setuptools.pypa.io/en/latest/userguide/development_mode.html) (`pip install -e`) 安装，方便开发者在不重新安装的情况下使更改立即生效。"

#: ../../source/installation.md:241
msgid "Extra information"
msgstr "额外信息"

#: ../../source/installation.md:243
msgid "Verify installation"
msgstr "验证安装"

#: ../../source/installation.md:245
msgid "Create and run a simple inference test. The `example.py` can be like:"
msgstr "创建并运行一个简单的推理测试。`example.py` 示例代码如下："

#: ../../source/installation.md:270
msgid "Then run:"
msgstr "然后执行："

#: ../../source/installation.md:276
msgid ""
"If you encounter a connection error with Hugging Face (e.g., `We couldn't"
" connect to 'https://huggingface.co' to load the files, and couldn't find"
" them in the cached files.`), run the following commands to use "
"ModelScope as an alternative:"
msgstr ""
"如果您遇到 Hugging Face 连接错误（例如：`We couldn't connect to 'https://huggingface.co'...`），请运行以下命令改用 ModelScope 镜像源："

#: ../../source/installation.md:284
msgid "The output will be like:"
msgstr "输出结果示例如下："

#: ../../source/installation.md:308
msgid "Multi-node Deployment"
msgstr "多节点部署"

#: ../../source/installation.md:309
msgid "Verify Multi-Node Communication"
msgstr "验证多节点通信"

#: ../../source/installation.md:311
msgid ""
"First, check physical layer connectivity, then verify each node, and "
"finally verify the inter-node connectivity."
msgstr "首先检查物理层连通性，然后验证单个节点，最后验证节点间的连通性。"

#: ../../source/installation.md:313
msgid "Physical Layer Requirements:"
msgstr "物理层要求："

#: ../../source/installation.md:315
msgid ""
"The physical machines must be located on the same WLAN, with network "
"connectivity."
msgstr "物理机必须位于同一局域网内，且网络互通。"

#: ../../source/installation.md:316
msgid ""
"All NPUs are connected with optical modules, and the connection status "
"must be normal."
msgstr "所有 NPU 均通过光模块连接，且连接状态必须正常。"

#: ../../source/installation.md:318
msgid "Each Node Verification:"
msgstr "单节点验证："

#: ../../source/installation.md:320
msgid ""
"Execute the following commands on each node in sequence. The results must"
" all be `success` and the status must be `UP`:"
msgstr "在每个节点上依次执行以下命令，结果必须全部为 `success` 且状态为 `UP`："

#: ../../source/installation.md
msgid "A2 series"
msgstr "A2 系列"

#: ../../source/installation.md
msgid "A3 series"
msgstr "A3 系列"

#: ../../source/installation.md:365
msgid "Interconnect Verification:"
msgstr "互联验证："

#: ../../source/installation.md:366
msgid "1. Get NPU IP Addresses"
msgstr "1.获取 NPU IP 地址"

#: ../../source/installation.md:388
msgid "2. Cross-Node PING Test"
msgstr "2.跨节点 PING 测试"

#: ../../source/installation.md:395
msgid "Run Container In Each Node"
msgstr "在每个节点运行容器"

#: ../../source/installation.md:397
msgid ""
"Using vLLM-ascend official container is more efficient to run multi-node "
"environment."
msgstr "使用 vLLM-ascend 官方容器可以更高效地运行多节点环境。"

#: ../../source/installation.md:399
msgid ""
"Run the following command to start the container in each node (You should"
" download the weight to /root/.cache in advance):"
msgstr "在每个节点运行以下命令启动容器（您应提前将模型权重下载到 /root/.cache）："