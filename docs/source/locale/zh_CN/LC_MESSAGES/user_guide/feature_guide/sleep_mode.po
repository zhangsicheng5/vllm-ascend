# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2025, vllm-ascend team
# This file is distributed under the same license as the vllm-ascend
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2025.
#
msgid ""
msgstr ""
"Project-Id-Version: vllm-ascend\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-21 10:23+0800\n"
"PO-Revision-Date: 2026-01-22 16:15+0800\n"
"Last-Translator: Gemini\n"
"Language: zh_CN\n"
"Language-Team: zh_CN <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../source/user_guide/feature_guide/sleep_mode.md:1
msgid "Sleep Mode Guide"
msgstr "睡眠模式"

#: ../../source/user_guide/feature_guide/sleep_mode.md:3
msgid "Overview"
msgstr "概述"

#: ../../source/user_guide/feature_guide/sleep_mode.md:5
msgid ""
"Sleep Mode is an API designed to offload model weights and discard KV "
"cache from NPU memory. This functionality is essential for reinforcement "
"learning (RL) post-training workloads, particularly in online algorithms "
"such as PPO, GRPO, or DPO. During training, the policy model typically "
"performs auto-regressive generation using inference engines like vLLM, "
"followed by forward and backward passes for optimization."
msgstr ""
"Sleep Mode 是一个旨在从 NPU 内存中卸载模型权重并丢弃 KV cache 的 API。此功能对于强化学习（RL）后训练（Post-training）任务至关重要，"
"特别是在 PPO、GRPO 或 DPO 等在线算法中。在训练过程中，策略模型通常先使用 vLLM 等推理引擎进行自回归生成，"
"随后进行前向和反向传播以进行优化。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:7
msgid ""
"Since the generation and training phases may employ different model "
"parallelism strategies, it becomes crucial to free KV cache and even "
"offload model parameters stored within vLLM during training. This ensures"
" efficient memory utilization and avoids resource contention on the NPU."
msgstr ""
"由于生成和训练阶段可能采用不同的模型并行策略，因此在训练期间释放 KV cache 甚至卸载存储在 vLLM 中的模型参数变得至关重要。"
"这可以确保内存的高效利用，并避免 NPU 上的资源竞争。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:9
msgid "Getting started"
msgstr "快速上手"

#: ../../source/user_guide/feature_guide/sleep_mode.md:11
#, python-brace-format
msgid ""
"With `enable_sleep_mode=True`, the way we manage memory (malloc, free) in"
" vllm is under a specific memory pool. During model loading and KV cache "
"initialization, we tag the memory as a map: `{\"weight\": data, "
"\"kv_cache\": data}`."
msgstr ""
"当设置 `enable_sleep_mode=True` 时，vLLM 管理内存（malloc, free）的方式将在特定的内存池下进行。"
"在模型加载和 KV cache 初始化期间，我们将内存标记为一个映射（Map）：`{\"weight\": data, \"kv_cache\": data}`。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:13
msgid ""
"The engine (v0/v1) supports two sleep levels to manage memory during idle"
" periods:"
msgstr "引擎（v0/v1）支持两种睡眠等级，以便在空闲期间管理内存："

#: ../../source/user_guide/feature_guide/sleep_mode.md:15
msgid "Level 1 Sleep"
msgstr "一级睡眠 (Level 1 Sleep)"

#: ../../source/user_guide/feature_guide/sleep_mode.md:16
msgid "Action: Offloads model weights and discards the KV cache."
msgstr "操作：卸载模型权重并丢弃 KV cache。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:17
msgid "Memory: Model weights are moved to CPU memory; KV cache is forgotten."
msgstr "内存：模型权重被移动到 CPU 内存；KV cache 被清除。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:18
msgid "Use Case: Suitable when reusing the same model later."
msgstr "用例：适用于稍后需要重复使用同一模型的情况。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:19
msgid "Note: Ensure sufficient CPU memory is available to hold the model weights."
msgstr "注意：请确保有足够的 CPU 内存来存放模型权重。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:21
msgid "Level 2 Sleep"
msgstr "二级睡眠 (Level 2 Sleep)"

#: ../../source/user_guide/feature_guide/sleep_mode.md:22
msgid "Action: Discards both model weights and KV cache."
msgstr "操作：同时丢弃模型权重和 KV cache。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:23
msgid "Memory: The content of both the model weights and KV cache is forgotten."
msgstr "内存：模型权重和 KV cache 的内容都会被清除。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:24
msgid ""
"Use Case: Ideal when switching to a different model or updating the "
"current one."
msgstr "用例：在切换到不同模型或更新当前模型时最为理想。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:26
msgid ""
"Since this feature uses the low-level API "
"[AscendCL](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/82RC1alpha002/API/appdevgapi/appdevgapi_07_0000.html),"
" in order to use sleep mode, you should follow the [installation "
"guide](https://docs.vllm.ai/projects/ascend/en/latest/installation.html) "
"and build from source. If you are using < v0.12.0rc1, remember to set "
"`export COMPILE_CUSTOM_KERNELS=1`."
msgstr ""
"由于此功能使用了底层 API [AscendCL](https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/82RC1alpha002/API/appdevgapi/appdevgapi_07_0000.html)，"
"为了使用睡眠模式，您应当参考 [安装指南](https://docs.vllm.ai/projects/ascend/en/latest/installation.html) 并从源码构建。"
"如果您使用的版本早于 v0.12.0rc1，请记得设置 `export COMPILE_CUSTOM_KERNELS=1`。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:28
msgid "Usage"
msgstr "使用方法"

#: ../../source/user_guide/feature_guide/sleep_mode.md:30
msgid "The following is a simple example of how to use sleep mode."
msgstr "以下是如何使用睡眠模式的一个简单示例。"

#: ../../source/user_guide/feature_guide/sleep_mode.md:32
msgid "Offline inference:"
msgstr "离线推理："

#: ../../source/user_guide/feature_guide/sleep_mode.md:72
msgid "Online serving:"
msgstr "在线服务："

#: ../../source/user_guide/feature_guide/sleep_mode.md:74
msgid ""
"Considering there may be a risk of malicious access, please make sure you"
" are under a dev-mode, and explicit specify the dev environment "
"`VLLM_SERVER_DEV_MODE` to expose these endpoints (sleep/wake up)."
msgstr ""
"考虑到可能存在恶意访问的风险，请确保您处于开发模式（Dev-mode），并显式指定开发环境环境变量 `VLLM_SERVER_DEV_MODE`，"
"以暴露这些接口端点（sleep/wake up）。"